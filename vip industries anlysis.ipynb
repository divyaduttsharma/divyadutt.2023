{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1bb89d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymupdf in c:\\users\\divya\\anaconda3\\lib\\site-packages (1.23.3)\n",
      "Requirement already satisfied: PyMuPDFb==1.23.3 in c:\\users\\divya\\anaconda3\\lib\\site-packages (from pymupdf) (1.23.3)\n",
      "Requirement already satisfied: textblob in c:\\users\\divya\\anaconda3\\lib\\site-packages (0.17.1)\n",
      "Requirement already satisfied: nltk>=3.1 in c:\\users\\divya\\anaconda3\\lib\\site-packages (from textblob) (3.7)\n",
      "Requirement already satisfied: click in c:\\users\\divya\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (7.1.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\divya\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (2022.3.15)\n",
      "Requirement already satisfied: joblib in c:\\users\\divya\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (1.1.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\divya\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (4.64.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\divya\\anaconda3\\lib\\site-packages (from tqdm->nltk>=3.1->textblob) (0.4.4)\n",
      "Requirement already satisfied: nltk in c:\\users\\divya\\anaconda3\\lib\\site-packages (3.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\divya\\anaconda3\\lib\\site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\divya\\anaconda3\\lib\\site-packages (from nltk) (4.64.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\divya\\anaconda3\\lib\\site-packages (from nltk) (2022.3.15)\n",
      "Requirement already satisfied: click in c:\\users\\divya\\anaconda3\\lib\\site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\divya\\anaconda3\\lib\\site-packages (from tqdm->nltk) (0.4.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install pymupdf\n",
    "!pip install textblob\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e42cc2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\divya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\divya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\divya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\divya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import pandas as pd\n",
    "import fitz  # PyMuPDF\n",
    "import re\n",
    "import pandas as pd\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import os\n",
    "import nltk\n",
    "import collections\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from textblob import TextBlob\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf8da92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = \"C:\\\\Users\\\\divya\\\\Downloads\\\\transcript\\\\files\\\\PRAJINDUSTRIES_PRAJIND.NS_06-02-2023.pdf\"\n",
    "pdf_reader = fitz.open(pdf_path)\n",
    "pdf_text = ''\n",
    "\n",
    "for page_num in range(len(pdf_reader)):\n",
    "    page = pdf_reader[page_num]\n",
    "    pdf_text += page.get_text()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41a50f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_all_caps(text):\n",
    "  \"\"\"Removes all words that are in all caps from a string.\"\"\"\n",
    "  words = text.split(\" \")\n",
    "  new_words = []\n",
    "  for word in words:\n",
    "    if not word.isupper():\n",
    "      new_words.append(word)\n",
    "  return \" \".join(new_words)\n",
    "\n",
    "def remove_names(text):\n",
    "  \"\"\"Removes all names from a string.\"\"\"\n",
    "  names = re.compile(r\"[A-Z][a-z]+\")\n",
    "  return names.sub(\"\", text)\n",
    "\n",
    "def remove_extra_spaces(text):\n",
    "  \"\"\"Removes extra spaces from a string.\"\"\"\n",
    "  return re.sub(r\"\\s+\", \" \", text)\n",
    "\n",
    "def remove_sentences_with_commas(text):\n",
    "  \"\"\"Removes sentences which just have \",\" and no words.\"\"\"\n",
    "  sentences = text.split(\".\")\n",
    "  new_sentences = []\n",
    "  for sentence in sentences:\n",
    "    if len(sentence.split(\",\")) == 1:\n",
    "      continue\n",
    "    new_sentences.append(sentence)\n",
    "  return new_sentences\n",
    "\n",
    "\n",
    "def most_frequent_words(text):\n",
    "  \"\"\"Finds the most frequent words in a text.\"\"\"\n",
    "  words = text.split(\" \")\n",
    "  counts = collections.Counter(words)\n",
    "  most_common = counts.most_common(50)\n",
    "  return most_common\n",
    "\n",
    "def remove_stopwords(text):\n",
    "  \"\"\"Removes stopwords from a text.\"\"\"\n",
    "  stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "  words = text.split(\" \")\n",
    "  new_words = []\n",
    "  for word in words:\n",
    "    if word not in stopwords:\n",
    "      new_words.append(word)\n",
    "  return \" \".join(new_words)\n",
    "\n",
    "def join_short_sentences(sentences):\n",
    "  \"\"\"\n",
    "  Joins sentences which are less than or equal to 3 words to append to the previous sentence.\n",
    "\n",
    "  Args:\n",
    "    sentences: A list of sentences.\n",
    "\n",
    "  Returns:\n",
    "    A list of joined sentences.\n",
    "  \"\"\"\n",
    "\n",
    "  joined_sentences = []\n",
    "  current_sentence = \"\"\n",
    "  for sentence in sentences:\n",
    "    if len(sentence.split()) <= 5:\n",
    "      current_sentence += \" \" + sentence\n",
    "    else:\n",
    "      if current_sentence:\n",
    "        joined_sentences.append(current_sentence)\n",
    "      current_sentence = sentence\n",
    "\n",
    "  if current_sentence:\n",
    "    joined_sentences.append(current_sentence)\n",
    "    #text = joined_sentences\n",
    "  return joined_sentences\n",
    "\n",
    "def lemmatize(text):\n",
    "    \"\"\"Lemmatize a text string.\n",
    "\n",
    "    Args:\n",
    "        text (str): The text string to lemmatize.\n",
    "\n",
    "    Returns:\n",
    "        str: The lemmatized text string.\n",
    "    \"\"\"\n",
    "\n",
    "    lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "    return lemmatizer.lemmatize(text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b391db44",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = re.sub(r'Page \\d+ of \\d+', '', pdf_text)\n",
    "text = remove_all_caps(text)\n",
    "text = remove_names(text)\n",
    "text = re.sub(r'â€“', '-', text)\n",
    "text = re.sub(r'[^a-zA-Z0-9\\s.,!?]', '', text)\n",
    "text = re.sub(r'good (morning|evening|afternoon)', '', text, flags=re.IGNORECASE)    \n",
    "text = re.sub(r'thank you', '', text, flags=re.IGNORECASE)\n",
    "text = re.sub(r'evening', '', text, flags=re.IGNORECASE)\n",
    "text = re.sub(r'morning', '', text, flags=re.IGNORECASE)\n",
    "text = re.sub(r'afternoon', '', text, flags=re.IGNORECASE)\n",
    "text = re.sub(r'ladies and gentlemen[.,]*', '', text, flags=re.IGNORECASE)\n",
    "text = re.sub(r'welcome', '', text, flags=re.IGNORECASE)\n",
    "text = re.sub(r'question', '', text, flags=re.IGNORECASE)\n",
    "text = re.sub(r'conference call', '', text, flags=re.IGNORECASE)\n",
    "text = re.sub(r'conference', '', text, flags=re.IGNORECASE)\n",
    "text = re.sub(r'call', '', text, flags=re.IGNORECASE)\n",
    "text = re.sub(r'record', '', text, flags=re.IGNORECASE)\n",
    "text = re.sub(r'recorded', '', text, flags=re.IGNORECASE)\n",
    "text = re.sub(r'last question', '', text, flags=re.IGNORECASE)\n",
    "text = re.sub(r'please', '', text, flags=re.IGNORECASE)\n",
    "text = re.sub(r'go ahead', '', text, flags=re.IGNORECASE)\n",
    "text = re.sub(r'page', '', text, flags=re.IGNORECASE)\n",
    "text = re.sub(r'you', '', text, flags=re.IGNORECASE)\n",
    "text = re.sub(r\"\\s+\", \" \", text)\n",
    "text = remove_stopwords(text)\n",
    "text = lemmatize(text)\n",
    "#text = re.sub(r'\\s+', ' ', text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9248df9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentences = join_short_sentences(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf688d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentences = remove_sentences_with_commas(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3e93e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " gentlemen, earnings . management team, us today, . , . , . , . , . begin, quick announcements attendees. said reflects outlook future, could construed forwardlooking statement may involve risks uncertainties. statements comments guarantees future performance, actual results may differ statements. , note earnings scheduled duration 45 minutes, starting directly section . wish ask , use raise hand feature available r dashboard. announce r name unmute r line, post proceed r . wait minute queue assembles. first line . . . , team, couple s. , food delivery side. progress margins front, think balance growth profitability quarter seen losses coming quite bit, growth also modest 3 quarteronquarter. think coming quarters mediumterm standpoint? , r , side. way thinking essentially focus good quality growth well profitability. yes, right, quarter growth low, largely traded lower quality growth business favor economics. far good quality growth concerned, define good quality acquire users going profitable future, now, retention going high, cost acquisition justified, makes total sense. one reasons saw slightly lower growth last quarter. second reason also general macros. dont want make excuse, weve seen lower app opens last quarter compared past, clearly demonstrates low intent spend category like ours. also quarter where, seasonally, high impact rains typiy leads muted growth look past trends. , reasons weve seen relatively lower growth last quarter. would say impact longterm view opportunity segment. continue remain bullish potential business take medium longterm perspective. , . followup that, whatever investor conversations today, investors worried. hear me? , can. , investors worry prioritize profitability get break even, obviously everybody expecting, two four quarters, continue weigh think till time focus break even continues, numbers lackluster, speak? really focusing break even important milestone. dont think driving business mind first goal. goal continues remain expand market set well years line, generate huge pools profits. , understand street treating big milestone, minds, one milestones along way, going compromise good quality growth get milestone faster. , add, like mentioned letter, continue invest longterm growth vectors, initiatives like . opportunities take time build grow, leaving stone unturned terms investing these. second last . first quarter consolidating numbers, fact, consolidation r impression side? negative surprises, key focus areas next quarters standpoint ? integration gone well, . havent surprises business far. also reaffirms faith approach case deals weve done past, want get know founders well business well proceed , answer first part r , yes, surprises. mentioned letter, excited business. seen numbers, business made good progress quarter compared previous quarter, top line bottom line, expect trend continue. wish best. . . line . . . , first look r growth, around 4.5. also made comment AO grown, growth 3, appears impact frequency. , case lost high frequency users, market share loss competition recent quarter? might deliberate strategy, trying confirm case. , dont think lost market share last quarter. frequency indeed gone slightly, reasons attributable mentioned response previous . hope answered r . , share power users would remained constant, , terms number users percentage total annual transacting users guys shared? . , got it. second mediumterm aspirations profitability guys shared. looks like lot revenueled levers already played out. trying understand driver perspective, one think contribution margin going 8 eventually? bigger drivers? revenue side room take ratescommission rates improve? bulk initiatives cost side yet play out, key driver margin improvement on. . , would say pretty much that. right, last couple quarters, revenue side levers played perhaps cost side. going forward, still think enough growth left improve revenue per order well drive costs down. cost side, two elements. driven scale, essentially making business leaner go along. think levers going play out, thats expecting next quarters go along. may squeeze last , exactly restructuring ad sales platform, going lead increased losses coming quarters? , mentioned 16 17 letter, launched new product customers dining out, along that, new monetization model driving transactions restaurants app. , customers paying app restaurants, transactions get monetized. switch transition new construct, erstwhile monetization streams sort discontinued, includes sale membership well sale restaurants buying ads platform. discontinued time being. hence, see losses expanding segment short term costs, weve lost revenue. thats transition going through, expect continue least next quarter maybe one quarter start see business generating profits again. . line . . . , opportunity. two s. , food delivery business, think r overall promotional budget spending QoQ basis new user acquisition driving better usage existing users? related that, could give approximate base annual transacting customers end repeat , ? lost second. . , first was, think promotional budget, incentive budget spending QoQ basis food delivery business things drive new user acquisition things drive better usage existing older customers? second part r total base annual transacting customers , , first one, majority promotional spends acquiring new users. spend capital on. said that, existing user , experience still get offers discounts platform. largely funded restaurants essentially trying target new customer particular restaurant. thats feel real user subsidies discounts time, always funded us. response second , disclosing data point every quarter, . , wait get that. . , guess point trying come was, think earlier mentioned typiy see maybe one million new users come onto platform little marketing spends also, get number right, one million maybe seven million ten million year, something like that. wondering still holding true end quarter? , holding true. pace new user addition hasnt slowed down. it. second side. parts. , delivery fleet integration side, practical ground challenges integrating two delivery fleets right away, rider preference perspective consideration? second is, terms unit economics, said r store materially different versus franchise stores. explain function store maturity? , . Ill take s. , rider side, mentioned letter well, integration primarily right leveraging common tech stack companies. probably mediumterm thing pick actually crossutilizing fleets. primary reason scale two businesses similar comes last mile size fleet well number orders done particular locality businesses. , till time actually get there, really even experimenting merging fleets right now. , numbers see fleet improvements, essentially riders working riders working only. places, started integrating tech stack, underlying platforms built, getting integrated tech efforts sides leveraged. economics side, store economics primarily dependent throughput. , infra people, actually push certain volume irrespective size store, every level, economics actually similar, whether store partner store. course, nature costs cases end differently. example, case partner stores, basiy make sure places number orders scaling materially early enough, support partners first months process. stores, would also taking cost terms idle manpower store well. , costs materially different. things changing though brand recognition brand value localities cities present in, goes up, time able see stores get certain number orders actually getting faster. costs pay partner side support them, getting scale lot faster, partners start making money lot faster. , quick one. dark store side, place would start net add dark stores going forward? theres still little bit rationalization go? secondly, look unit economics, right way look r unit economics expense related dark store perstore basis, see number roughly 5 million quarter, kind around number last two quarters reported. understanding correct? , , throughout last two quarters, adding stores network. net store deletion number higher earlier multiple reasons. opened stores which, infrastructurally, could right places because, obviously, model early. experience net store addition pace us stays roughly across months. starting see stores successful. , net deletion pace something going go down. overall number new store openings go up. still internally us, store network fairly large number around 400 pace, opening stores opportunities, localities existing successful stores validation. , opening stores, reducing store openings number stores go up, thats something still stage debating whether investing behind it. think wait overall existing store likeforlike network breaking even. r second around unit economics stores, mentioned earlier, unit economics stores primarily move infrastructure, people, increase net revenue get store increasing thats seeing number stay overall throughput business gone dramatiy. roughly speaking, maybe 2.0x 2.5x number orders per store, break even company level across board seems case unit economics? think difference arithmetic versus it, guidance providing point time. , appreciate it. . . line . . opportunity. , r AO held well actually last quarters. , could help us understand difference AO see new old customers? also, customers might in, lets say, top 10 cities cities? , sure, . new customers lower repeat customers. , trajectory customers mature, starts going settles steady level. tier1 smaller cities well, difference AO. AO larger smaller cities. said that, want clarify doesnt mean smaller cities economics viable, weve also shared chart time number cities profitable. even lower AO, given lower cost structures, number smaller cities also profitable. . second really terms growth food delivery platform. competitor market, think r focus would also driving kind differentiation. highlight new aspects, new product innovation, etc., carrying food delivery business differentiated platform going forward? , . , differentiation many aspects. things focus lot quality service, really visible app. customer, experience platform, error rates business customer support on, adds up. , theres consistent focus making platform experience better customers every day. compounding effect growth relative market share business. that, mentioned letter also, keenly looking large growth ideas drive multiplier outcomes category future. couple experimenting right , 10 15minute food delivery service already live locations across . recently, weve launched productservice delivering food legendary restaurants across cities. , ideas far seen good traction, seeing lot customer love appreciation products services. businesses multiple building blocks, weve spent time, effort, resources scaling up. would say cautiously investing scale, well continue long continue see returns two products services. point, safe assume new initiatives going done organiy within company, correct? , thats current plan. dont even think theres opportunity inorganic route things. knowledge resources have, need able scale platforms. , much r answers. . line . . go ahead. , number cities point made one mentioned investor letter now, 248 cities contribution break even trying understand number fairly low, lets say, four quarters ago revenue measures taken, instance, higher take rate restaurants customer delivery charges going up, right assume initiatives across cities less uniformly applied? one. two, terms smallest city contribution positive, kind household total population size household size looking at? mean, trying get sense kind population model become viable already. . , r first , yes, seen improvement contribution pretty much uniformly across multiple cities. think still contribution negative recently launched cities cities flywheel restaurant food ordering really kicked yet. see enough traction underlying consumer metrics continue invest. outside that, everywhere else, weve seen contribution improve. hence, larger number cities contribution break even positive. terms smaller cities, way, clarify, 248 doesnt necessarily mean top 248 cities us terms size. profitable cities actually top 248, theyre still profitable ecosystem maturing faster larger cities. r second , smaller cities contribution break even positive 100,000 people today, potential size market. loosely ing cities, also locations dense population neighborhoods like universities, towns population large. slightly close 50,000, breaking even densely located, target audience values service product. second one . , investor letter, mentioned festive season certain days , whole, near contribution positive. Im trying understand driving wins. , 7 negative contribution, 7 0, operating leverage driven higher orders, product assortment, perhaps higher take rate higher delivery fees customers willing pay time? Im trying get sense model become profitable going forward. . shown contribution movement graph letter, wish easier answer give that. see pattern took us 17 7 contribution threemonth period also driving contribution break even festive period well. , singular factor improvements across average ticket size, improvements across average revenue per order reduction costs. also, clarify, festive period, didnt want ones ruining festive period customers, actually charging higher delivery fees them. always try make sure business working towards charging lower lower delivery fees customers. , best. . line . . go ahead. , two quick s. first one seven r see food delivery restaurant partners kind stagnated around 200,000 number last three quarters. part might pruning lower quality growth, mentioned, could give us indication kind additions looking at? would like believe lead indicator terms getting customers platform. , , like case dark stores, mentioned, net number. , happened continued add thousands new restaurants platform every month, net number actually remained flat, see pointing out. thats essentially function restaurants shutting country. pace, actually, dont dictate, decent number restaurants platform low order volumes low share business us churn out, overall number restaurants stay flat come slightly, happened. concerned supply constrained, least point. look number orders per restaurant per day, theyre still low, expect supply number restaurants continue increasing medium long term, even base restaurants, business grow meaningfully to, yes. , . second longterm target guys mentioned would like go 4 5 margin percentage translates roughly 8 contribution margin. Im trying get sense went behind precise numbers. remember correctly, mentioning think doubledigit contribution margin likely mature cities longerterm period. , scaling back 10 target? . , first all, guidance, neither saying going stop 4 5. point view shared point time. know perhaps better use capital beyond point going making sure reinvest back ecosystem, leads faster growth. eventually, goal get dollar profits business, goal get maximum percentage margin. going goal, cash business generates, look best that. best giving discounts customers, best actually giving back ecosystem terms lower take rates higher pats, leads growth ecosystem think always choice. shared time around feel beyond point, perhaps higher leave money table restaurants grow faster, pay riders retention higher on. second part r 8 10, pulling back guidance. said, cities could get 10. 8 average. still go beyond 8, would urge focus core message numbers are, would say, indicative feel point time, change go along. , best. . line . , joining retail investor. . is, look earnings report, mean, Im sure lots financial experts would ask earnings. r mean, two, say execute better, mean? that, find one paragraph guess, relevant investors well culture high standards endless list things. starting point culture present physiy, intellectually. earnings , retail investor allowed speak. speaking number given, allowed speak. pertinent corporate governance. , say r earnings letter, doesnt fit in. pertinent conflict interest disclosed. day deal, markets opened, many people didnt know it. news channels started speaking it, know happened stock entire perception people, mean, look like scam even scam scam, dont know, perception something else. know happened stock. may taken leverage positions may lost shirt may money fund it. , guess serious corporate governance issues needs think about. , obviously, us feel purchased high price. theres ESO. mean, company still loss, ESO doled out. , would like address things. that, last earnings , someone said, isnt loyalty program? many people today asking gross order value number orders expansion, rather, expansion, new customers, come down. competitor loyalty program membership. doesnt. , guess person asked last earnings point loyalty program, kind membership, could regular customers order maybe two times day, maybe every day, may want see something like fixed monthly fee delivery forth. yes, say. . , . , r first , zoom out, general, tend endeavor operate without biases idea give preference particular class shareholders, idea actually give equal opportunity shareholders. may situations weve adequate time address s, people write us. always available address queries. , r point noted, ensure situations reason complain going forward. yes, broader philosophy operate bias. r second point around conflict interest, there, philosophy, operate highest standards diligence processes per global standards. case potential conflict talking about, responded well director such, per applicable law, reason related party transaction, even involved discussions deal. law spirit, weve tried anything outside high standards hold terms diligence process. terms valuation well, weve best global firms advise us valuation. valuation reports made available public inspection, again, responded feedback. , things, hold highest standards, continue so. r point regarding ESO, weve also, letter, one tried address human capital important critical tech businesses. speed innovation experimentation need stay alive stay ahead purely people dependent. us able attract best talent, also offer right incentives packages attract right talent. go talent marketplace, attract best talent best tech companies globally, need offer that. cost whether paid cash ESO different matter, yes, think important long term investment business eventually lead profitability us. , r response terms terms , maybe required law, markets dont work purely. work perception various things. , guess, disclosure, take positive thing. mean, someone ing disclosure made beforehand, people who, markets opened deal, would information could taken informed decision. sudden, came surprise. 10 minutes markets, every news channel top voice talking this. sometimes maybe required law, required otherwise various reasons, explained. one thing said theres loyalty program. earnings , institutional investor raise it, think would help company. mean, order lot outside. , , loyalty program, aware competition doing. also one own, discontinued. , business pros cons form loyalty program market today. are, speak, working creating something differentiated. believe, least, perhaps make sure get benefit customers loyalty without really losing lot money. , would request wait watch that, well come back loyalty program construct soon market. right. mean, thing app several months now, so. yes, mean, okay, lets see. . . line . . . quick clarification this, impact gradual phaseout volume growth quarter? something kind resulted either lower volume number orders order frequency? second part given r market share stable, portion impact came seasonality versus move towards lower customer spends terms focus good quality customers? , . , looking combination various things mentioned first part r membership. stopped selling new memberships, still members continuing use service till membership expires. customers membership expired, least frequent customers, havent really seen much fall frequency post membership expiring. , may contributed form terms lower growth, multiple variables impacting overall order volumes quarter. , hard isolate impact one these. hence, would unable give color overall impact one overall performance quarter. . basiy, trying understand going which, again, really high quarter guys. something expect growth meaningfully strong, given seasonality normalization ad spending cuts, kind getting base? impacts kind still going system? , , would want give guidance next quarter point time. enough. second letter, mentioned pocketed large portion lowhanging gains now. referring take rate commentary? obviously seen meaningful improvement take rate last three quarters, much scope left? quarter discuss area still meaningful scope. captured now, referring something else? , referring essentially overall pace improvement contribution. , see last two quarters, contribution percentage grown 1.7 2.8 4.5 last quarter. , pace change sharp, thats opportunities revenue cost side. comment simply telling everyone dont expect pace improvement continue, pace improvement slow down. doesnt mean either revenue improvement slowing cost. continue work levers see opportunity improve margins, overall margin expansion pace, want shareholders know, slow going forward, least now. . get that. again, following last quarter, expect take rate normalization restaurants initially low continue done last two quarters three quarters, also something start feeling impact base effect? work progress, . business essentially done, cant make progress. opportunities across board take rate also area might see improvement going forward. would want specifiy discuss specific lever growth. want leave saying overall margin improvement, enough scope long term. journey today 8 mentioned involve improvement revenue cost side. . one final clarification. look revenue adjusted revenue, difference 5 million. , difference r reported revenue delivery charge. breakup obviously, cannot low, something wrong reading something come numbers? , business model different. customer delivery charge get customers revenue business. , already ed revenue. pretty much revenue business same, unlike food delivery, customer delivery charge passed delivery partners directly. . side. . . gentlemen, extending 10 minutes move towards last s. line . . . opportunity, continuing last participants contribution margin improvement. levers think would delivery cost pay riders. see competition outsourcing deliveries third parties. , past, understand like managing fleet majorly. , change strategy there, thinking along lines? thoughts that? , . dont think theres plan outsource. planning outsource meaningful portion delivery fleet third parties. small portion delivery fleet outsourced. far know, cheapest delivery service country today. least point, dont see much merit outsourcing already here. clarify, earlier number shared 94 deliveries taking r fleet. number continuing with, like material change this? now. material would say majority done directly us. , good. , next business model. , know nascent investment right now, thoughts plan monetize new venture trying? , right, still early days. main monetization continue ad sales. changed ads restaurants platform tangible visible terms transactions customers restaurants. essentially increases confidence restaurants spend ads platform, think going lead better monetization line. , thats broad strategy, well share results going perhaps next quarter well data us. far, recent launch, weeks it, early share data point. last one quick commerce. comments shareholder letter says ecommerce turning another opportunity . , would like understand, like, synergies looking cost side, revenue side? think it? , . primary integration time joining forces figure whether directfromfarm sourcing large part fresh produce sellers need also needs able supply restaurants. look vision statement, figure system getting better food people. adding mix allows us able two things once, improve scale sourcing farms directly, able give opportunities farmers areas access wider market. thats option presenting sellers well partner , able get better quality produce faster farms, something also helps overall sourcing ecosystem. thats working on. obviously services able offer sellers uses restaurant partners well, something still process developing. , synergy right exploring working direct fromfarm sourcing. . timeline see synergies reflecting numbers? , would like comment that? , primarily, look customers love around quality fresh produce, metrics would already reflecting there, dont think going see separate breakout it. economic impact something also probably baked somewhere commissions able charge sellers, going able see specific breakout integration. , customer ordering , quality produce consistently keep going up. , lot. . line . . . candid remarks commentary. , two s. concentration. , past, spoken r top 8 top 10 kind cities. able share proportion kind cohort account gross order values maybe even contribution profit? , , here. havent put data out, hasnt changed meaningfully past. larger point top 10 markets beyond top 10 continue grow see growth new user addition perspective well order volumes perspective. , point, dont see reason mix change substantially. terms growth gross order value cohort top 8, top 10, thats consistent broader theme, fair comment make? correct. . second piece kind cost optimization. point scale, global models, weve seen scale necessarily drive costs and, therefore, improve profitability, right? optimization dynamic. , looking kind optimize delivery costs, etc., speak practical challenges facing today? , , continuous process. fleet grown almost 300,000 delivery partners across multiple cities. journey last 23 years, learned incrementally make better experience delivery partners, better earning opportunity delivery partners ensuring customer service also continues better. , constant challenge learning process us. mean, isnt specific practical challenge emerged would like highlight point. maybe final piece, right? , terms contribution profit 4.5, specific . , think solid baseline work incremental basis, i.e., 4.5 next quarter kind risk sides? hope so, , go here. . . gentlemen, conclude . joining, may disconnect r lines. , everyone. \n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed890503",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sentences = sent_tokenize(text)\n",
    "# Remove stopwords and punctuations\n",
    "stop_words = set(stopwords.words('english'))\n",
    "filtered_sentences = []\n",
    "for sent in sentences:\n",
    "    words = word_tokenize(sent)\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words and word.isalnum()]\n",
    "    filtered_sentences.append(' '.join(filtered_words))\n",
    "    filtered_sentences = join_short_sentences(filtered_sentences)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809ee03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform sentiment analysis\n",
    "sentiments = {'positive': 0, 'neutral': 0, 'negative': 0}\n",
    "for sent in filtered_sentences:\n",
    "    blob = TextBlob(sent)\n",
    "    polarity = blob.sentiment.polarity\n",
    "    if polarity > 0.2:\n",
    "        sentiments['positive'] += 1\n",
    "    elif polarity == 0:\n",
    "        sentiments['neutral'] += 1\n",
    "    else:\n",
    "        sentiments['negative'] += 1\n",
    "\n",
    "# Display the sentiment analysis results\n",
    "sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8b32ecb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24.84472049689441, 37.88819875776397, 37.267080745341616, 25.465838509316768)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Calculate the total number of sentences\n",
    "total_sentences = sentiments['positive'] + sentiments['neutral'] + sentiments['negative']\n",
    "\n",
    "# Calculate the percentage of positive, neutral, and negative sentences\n",
    "positive_percent = (sentiments['positive'] / total_sentences) * 100\n",
    "neutral_percent = (sentiments['neutral'] / total_sentences) * 100\n",
    "negative_percent = (sentiments['negative'] / total_sentences) * 100\n",
    "\n",
    "# Calculate the overall sentiment score\n",
    "overall_score = neutral_percent + positive_percent - negative_percent\n",
    "\n",
    "# Display the calculated percentages and overall score\n",
    "positive_percent, neutral_percent, negative_percent, overall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aef355d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VADER Weighted Average: 0.3374717557251909\n",
      "FinBERT Weighted Average: 0.5095118650907019\n",
      "TextBlob Weighted Average: 0.12828294679541954\n"
     ]
    }
   ],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "import torch\n",
    "import numpy\n",
    "import math \n",
    "import transformers\n",
    "# Initialize VADER sentiment analyzer\n",
    "vader_analyzer = SentimentIntensityAnalyzer()\n",
    "vader_polarity_list = []  \n",
    "vader_labels = []  \n",
    "textblob_polarity_list = []\n",
    "textblob_labels = []\n",
    "finbert_polarity_list = []  \n",
    "finbert_labels = []  \n",
    "\n",
    "# Initialize FinBERT sentiment analyzer\n",
    "finbert_model = AutoModelForSequenceClassification.from_pretrained('yiyanghkust/finbert-tone', num_labels=3)\n",
    "finbert_tokenizer = AutoTokenizer.from_pretrained('yiyanghkust/finbert-tone')\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"yiyanghkust/finbert-tone\",num_labels=3)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"yiyanghkust/finbert-tone\")\n",
    "def get_finbert_sentiment(text):\n",
    "\n",
    "    label_list=['positive','negative','neutral']\n",
    "\n",
    "    ml_polarity = []\n",
    "    ml_sent = []\n",
    "    \n",
    "    for i in text:\n",
    "        if i == str(numpy.nan):\n",
    "            ml_sent.append('neutral')\n",
    "            ml_polarity.append(0)\n",
    "        else:\n",
    "            inputs = finbert_tokenizer(i, return_tensors=\"pt\", truncation=True)\n",
    "            outputs = model(**inputs)\n",
    "            prob_0 = math.exp(outputs.logits[0][0]) / (1 + math.exp(outputs.logits[0][0]))\n",
    "            prob_1 = math.exp(outputs.logits[0][1]) / (1 + math.exp(outputs.logits[0][1]))\n",
    "            polarity_score = prob_0 - prob_1\n",
    "\n",
    "            # Custom threshold for determining sentiment\n",
    "            if polarity_score > 0.5:\n",
    "                ml_sent.append('positive')\n",
    "            elif polarity_score < -0.5:\n",
    "                ml_sent.append('negative')\n",
    "            else:\n",
    "                ml_sent.append('neutral')\n",
    "\n",
    "            ml_polarity.append(polarity_score)\n",
    "    \n",
    "    return ml_polarity , ml_sent\n",
    "\n",
    "\n",
    "# Perform sentiment analysis using VADER and FinBERT\n",
    "vader_sentiments = {'positive': 0, 'neutral': 0, 'negative': 0}\n",
    "finbert_sentiments = {'positive': 0, 'neutral': 0, 'negative': 0}\n",
    "textblob_sentiments = {'positive': 0, 'neutral': 0, 'negative': 0}\n",
    "\n",
    "        \n",
    "\n",
    "def calculate_weighted_average(sentiment_counts, polarity_list, labels):\n",
    "    \"\"\"\n",
    "    Calculate weighted average sentiment score.\n",
    "\n",
    "    Parameters:\n",
    "    - sentiment_counts (dict): Dictionary containing the counts of each sentiment label.\n",
    "    - polarity_list (list): List of polarity scores for each sentence.\n",
    "    - labels (list): List of sentiment labels for each sentence.\n",
    "\n",
    "    Returns:\n",
    "    - weighted_avg (float): The weighted average sentiment score.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Calculate the total number of sentences\n",
    "    total_sentences = sum(sentiment_counts.values())\n",
    "    \n",
    "    # Initialize the sum for the weighted average calculation\n",
    "    weighted_sum = 0.0\n",
    "    \n",
    "    # If there are no sentences, return 0\n",
    "    if total_sentences == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    for sentiment, count in sentiment_counts.items():\n",
    "        # Calculate the average polarity for the current sentiment label\n",
    "        avg_polarity = sum(polarity for polarity, label in zip(polarity_list, labels) if label == sentiment) / count if count > 0 else 0.0\n",
    "        \n",
    "        # Add to the weighted sum\n",
    "        weighted_sum += avg_polarity * count\n",
    "    \n",
    "    # Calculate the weighted average\n",
    "    weighted_avg = weighted_sum / total_sentences\n",
    "    \n",
    "    return weighted_avg\n",
    "\n",
    "for sent in filtered_sentences:\n",
    "    # VADER\n",
    "    vader_score = vader_analyzer.polarity_scores(sent)['compound']\n",
    "    if vader_score > 0.5:\n",
    "        vader_sentiments['positive'] += 1\n",
    "        vader_labels.append('positive')\n",
    "    elif vader_score == 0:\n",
    "        vader_sentiments['neutral'] += 1\n",
    "        vader_labels.append('neutral')\n",
    "    else:\n",
    "        vader_sentiments['negative'] += 1\n",
    "        vader_labels.append('negative')\n",
    "    vader_polarity_list.append(vader_score)\n",
    "\n",
    "    # FinBERT\n",
    "    finbert_polarity, finbert_label = get_finbert_sentiment([sent])\n",
    "    finbert_polarity_list.extend(finbert_polarity)\n",
    "    finbert_labels.extend(finbert_label)\n",
    "    for label in finbert_label:\n",
    "        finbert_sentiments[label] += 1\n",
    "    # TextBlob\n",
    "    blob = TextBlob(sent)\n",
    "    polarity = blob.sentiment.polarity\n",
    "    if polarity > 0.5:\n",
    "        textblob_sentiments['positive'] += 1\n",
    "        textblob_labels.append('positive')\n",
    "    elif polarity == 0:\n",
    "        textblob_sentiments['neutral'] += 1\n",
    "        textblob_labels.append('neutral')\n",
    "    else:\n",
    "        textblob_sentiments['negative'] += 1\n",
    "        textblob_labels.append('negative')\n",
    "    textblob_polarity_list.append(polarity)\n",
    "\n",
    "# Display the sentiment analysis results\n",
    "vader_sentiments, finbert_sentiments\n",
    "\n",
    "# Calculate weighted averages\n",
    "vader_weighted_avg = calculate_weighted_average(vader_sentiments, vader_polarity_list, vader_labels)\n",
    "finbert_weighted_avg = calculate_weighted_average(finbert_sentiments, finbert_polarity_list, finbert_labels)\n",
    "textblob_weighted_avg = calculate_weighted_average(textblob_sentiments, textblob_polarity_list, textblob_labels)\n",
    "\n",
    "# Display the results\n",
    "print(\"VADER Weighted Average:\", vader_weighted_avg)\n",
    "print(\"FinBERT Weighted Average:\", finbert_weighted_avg)\n",
    "print(\"TextBlob Weighted Average:\", textblob_weighted_avg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821cb4d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "38562776",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26596255732153523"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined = (vader_weighted_avg+finbert_weighted_avg+textblob_weighted_avg)/3\n",
    "combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "057ed7d0",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'str' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [21]\u001b[0m, in \u001b[0;36m<cell line: 17>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m     weighted_avg_score \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m count \u001b[38;5;241m/\u001b[39m total_weight \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m sentiment \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     15\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m weighted_avg_score\n\u001b[1;32m---> 17\u001b[0m vader_weighted_avg_score \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_weighted_avg_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvader_counts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m finbert_weighted_avg_score \u001b[38;5;241m=\u001b[39m calculate_weighted_avg_score(finbert_counts)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Display the weighted average score for each model\u001b[39;00m\n",
      "Input \u001b[1;32mIn [21]\u001b[0m, in \u001b[0;36mcalculate_weighted_avg_score\u001b[1;34m(counts)\u001b[0m\n\u001b[0;32m     12\u001b[0m weighted_avg_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sentiment, count \u001b[38;5;129;01min\u001b[39;00m counts\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m---> 14\u001b[0m   weighted_avg_score \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m count \u001b[38;5;241m/\u001b[39m total_weight \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msentiment\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m weighted_avg_score\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'str' and 'int'"
     ]
    }
   ],
   "source": [
    "# Calculate the frequency of each sentiment for each model\n",
    "vader_counts = {}\n",
    "finbert_counts = {}\n",
    "\n",
    "for sentiment in ['positive', 'neutral', 'negative']:\n",
    "  vader_counts[sentiment] = vader_sentiments[sentiment]\n",
    "  finbert_counts[sentiment] = finbert_sentiments[sentiment]\n",
    "\n",
    "# Calculate the weighted average score for each model based on frequency\n",
    "def calculate_weighted_avg_score(counts):\n",
    "  total_weight = sum(counts.values())\n",
    "  weighted_avg_score = 0\n",
    "  for sentiment, count in counts.items():\n",
    "    weighted_avg_score += count / total_weight * (2 * sentiment - 1)\n",
    "  return weighted_avg_score\n",
    "\n",
    "vader_weighted_avg_score = calculate_weighted_avg_score(vader_counts)\n",
    "finbert_weighted_avg_score = calculate_weighted_avg_score(finbert_counts)\n",
    "\n",
    "# Display the weighted average score for each model\n",
    "print('VADER weighted average score:', vader_weighted_avg_score)\n",
    "print('FinBERT weighted average score:', finbert_weighted_avg_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "013c91e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'positive': 24.84472049689441,\n",
       "  'neutral': 37.88819875776397,\n",
       "  'negative': 37.267080745341616},\n",
       " 25.465838509316768,\n",
       " {'positive': 59.006211180124225,\n",
       "  'neutral': 16.149068322981368,\n",
       "  'negative': 24.84472049689441},\n",
       " 50.31055900621118,\n",
       " {'positive': 63.35403726708074,\n",
       "  'neutral': 8.074534161490684,\n",
       "  'negative': 28.57142857142857},\n",
       " 42.85714285714286)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sentiment counts obtained from VADER and FinBERT\n",
    "vader_counts = vader_sentiments\n",
    "finbert_counts = finbert_sentiments\n",
    "\n",
    "# Function to calculate sentiment percentages and overall score\n",
    "def calculate_sentiment_metrics(counts):\n",
    "    total = sum(counts.values())\n",
    "    percentages = {k: (v / total) * 100 for k, v in counts.items()}\n",
    "    overall_score = percentages['neutral'] + percentages['positive'] - percentages['negative']\n",
    "    return percentages, overall_score\n",
    "\n",
    "# Calculate sentiment metrics for TextBlob, VADER, and FinBERT\n",
    "textblob_metrics, textblob_score = calculate_sentiment_metrics(sentiments)\n",
    "vader_metrics, vader_score = calculate_sentiment_metrics(vader_counts)\n",
    "finbert_metrics, finbert_score = calculate_sentiment_metrics(finbert_counts)\n",
    "\n",
    "# Display the calculated metrics and overall scores\n",
    "textblob_metrics, textblob_score, vader_metrics, vader_score, finbert_metrics, finbert_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6d45f18b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Data for plotting\n",
    "labels = ['Positive', 'Neutral', 'Negative']\n",
    "textblob_values = [textblob_metrics['positive'], textblob_metrics['neutral'], textblob_metrics['negative']]\n",
    "vader_values = [vader_metrics['positive'], vader_metrics['neutral'], vader_metrics['negative']]\n",
    "finbert_values = [finbert_metrics['positive'], finbert_metrics['neutral'], finbert_metrics['negative']]\n",
    "\n",
    "# Set up the figure and axis\n",
    "x = np.arange(len(labels))\n",
    "width = 0.2\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Plotting\n",
    "rects1 = ax.bar(x - width, textblob_values, width, label='TextBlob')\n",
    "rects2 = ax.bar(x, vader_values, width, label='VADER')\n",
    "rects3 = ax.bar(x + width, finbert_values, width, label='FinBERT')\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels\n",
    "ax.set_ylabel('Percentage (%)')\n",
    "ax.set_title('Sentiment Analysis Comparison')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289213e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a dictionary to store the sentiment scores\n",
    "sentiments = {'VADER': {}, 'FinBERT': {}, 'TextBlob': {}}\n",
    "\n",
    "# Iterate over the sentences and add the sentiment scores to the dictionary\n",
    "for sent in filtered_sentences:\n",
    "    vader_score = vader_analyzer.polarity_scores(sent)['compound']\n",
    "    finbert_label = get_finbert_sentiment(sent)\n",
    "    textblob_polarity = TextBlob(sent).sentiment.polarity\n",
    "\n",
    "    sentiments['VADER'][sent] = vader_score\n",
    "    sentiments['FinBERT'][sent] = finbert_label\n",
    "    sentiments['TextBlob'][sent] = textblob_polarity\n",
    "\n",
    "# Create a Pandas DataFrame\n",
    "df = pd.DataFrame(sentiments)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e575570a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the DataFrame\n",
    "df.to_excel('results.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3795c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd6743d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e719079",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbc9920",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9dd9ac6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
